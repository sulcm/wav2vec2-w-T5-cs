{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "from datasets import Dataset, Audio, load_dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"mozilla-foundation/common_voice_11_0\"\n",
    "NAME = \"cs\"\n",
    "SPLIT = \"test\"\n",
    "SAMPLING_RATE = 16_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = load_dataset(DATASET_NAME, NAME, split=SPLIT)\n",
    "hf_dataset = hf_dataset.cast_column(\"audio\", Audio(sampling_rate=SAMPLING_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7714/7714 [00:26<00:00, 289.54it/s]\n"
     ]
    }
   ],
   "source": [
    "wav_lenghts = np.array([len(example['audio']['array']) for example in tqdm(hf_dataset.to_iterable_dataset(), total=len(hf_dataset))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_lenghts_secs = wav_lenghts/SAMPLING_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5338156922478605"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(wav_lenghts_secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34973.85425, 9.714959513888887)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_secs = np.sum(wav_lenghts_secs)\n",
    "total_secs, total_secs/3600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training table sumarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = glob('/home/sulcm/models/wav2vec2/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_latex_table(results: dict, best_results: dict) -> str:\n",
    "    formated_table = ''\n",
    "    for run, metrics in results.items():\n",
    "        formated_table += run + ' & ' + ' & '.join([f'\\\\textbf{{{v}}}' if run == best_results[m][0] else v for m, v in metrics.items()]) + ' \\\\\\\\\\n'\n",
    "    \n",
    "    return formated_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'v3': {'wer': '12.63', 'cer': '2.92'}, 'v1': {'wer': '16.49', 'cer': '3.70'}, 'baseline': {'wer': '12.73', 'cer': '2.91'}, 'v2': {'wer': '14.47', 'cer': '3.24'}, 'v4': {'wer': '13.42', 'cer': '3.07'}, 'v5': {'wer': '12.90', 'cer': '2.95'}, 'v6': {'wer': '11.58', 'cer': '2.66'}, 'v7': {'wer': '11.73', 'cer': '2.71'}, 'v8': {'wer': '11.71', 'cer': '2.79'}, 'v13': {'wer': '14.80', 'cer': '3.29'}, 'v16': {'wer': '14.83', 'cer': '3.37'}}\n",
      "{'wer': ('v6', 0.11579490391878697), 'cer': ('v6', 0.026599265812120118)}\n"
     ]
    }
   ],
   "source": [
    "metrics = ['wer', 'cer']\n",
    "best_results = dict.fromkeys(metrics, ('', 1.0))\n",
    "table_prep = {}\n",
    "\n",
    "for train_res in train_paths:\n",
    "    path2res = train_res + '/all_results.json'\n",
    "    if not os.path.exists(path2res):\n",
    "        continue\n",
    "\n",
    "    with open(path2res, 'r') as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    table_prep[train_res.split('/')[-1].split('-')[-1]] = {m: f'{100.0*results[f\"eval_{m}\"]:.02f}' for m in metrics}\n",
    "\n",
    "    for metric in metrics:\n",
    "        if best_results[metric][1] > results[f\"eval_{metric}\"]:\n",
    "            best_results[metric] = (train_res.split('/')[-1].split('-')[-1], results[f\"eval_{metric}\"])\n",
    "\n",
    "print(table_prep)\n",
    "print(best_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v3 & 12.63 & 2.92 \\\\\n",
      "v1 & 16.49 & 3.70 \\\\\n",
      "baseline & 12.73 & 2.91 \\\\\n",
      "v2 & 14.47 & 3.24 \\\\\n",
      "v4 & 13.42 & 3.07 \\\\\n",
      "v5 & 12.90 & 2.95 \\\\\n",
      "v6 & \\textbf{11.58} & \\textbf{2.66} \\\\\n",
      "v7 & 11.73 & 2.71 \\\\\n",
      "v8 & 11.71 & 2.79 \\\\\n",
      "v13 & 14.80 & 3.29 \\\\\n",
      "v16 & 14.83 & 3.37 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(format_latex_table(table_prep, best_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
