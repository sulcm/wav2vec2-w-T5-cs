{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, T5Tokenizer, T5ForConditionalGeneration\n",
    "from datasets import Dataset, load_dataset, Audio, DatasetDict, load_from_disk\n",
    "import evaluate\n",
    "import jiwer\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from IPython.display import Audio as AudioDisp\n",
    "\n",
    "from asr_w_spellchecker import ST6\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = {\n",
    "    # \"path\": \"facebook/voxpopuli\",\n",
    "    \"path\": \"mozilla-foundation/common_voice_11_0\",\n",
    "    \"name\": \"cs\",\n",
    "    \"split\": \"test\"\n",
    "}\n",
    "\n",
    "SAMPLING_RATE = 16_000\n",
    "\n",
    "WAV2VEC_MODEL_NAME = \"/home/sulcm/models/wav2vec2/wav2vec2-cs-v23\"\n",
    "\n",
    "T5_MODEL_NAME = \"/home/sulcm/models/t5/t5-spellchecker-cs-v4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(DATASET['path'], DATASET['name'], split=DATASET['split'])\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=SAMPLING_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"/home/sulcm/datasets/t5/asr-correction-cs-v23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st6_model = ST6(wav2vec2_path=WAV2VEC_MODEL_NAME, t5_path=T5_MODEL_NAME, logging_level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav2vec_processor = Wav2Vec2Processor.from_pretrained(WAV2VEC_MODEL_NAME)\n",
    "wav2vec_model = Wav2Vec2ForCTC.from_pretrained(WAV2VEC_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_tokenizer = T5Tokenizer.from_pretrained(T5_MODEL_NAME)\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained(T5_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = t5_tokenizer([\"spell check: \" + sentence for sentence in dataset[\"normalized_text\"]], return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(np.count_nonzero(inputs.input_ids, axis=1), q=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = eval_metrics = {metric: evaluate.load(metric) for metric in [\"sacrebleu\", \"wer\", \"cer\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1500\n",
    "\n",
    "input_audio = dataset[idx]['audio']\n",
    "sentence = dataset[idx]['sentence'].lower()\n",
    "\n",
    "print(sentence)\n",
    "AudioDisp(input_audio['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st6_model(input_audio['array'], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = st6_model([d['array'] for d in dataset['audio']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenstein(ref_word: str, comp_word: str) -> int:\n",
    "    # mx = []\n",
    "    prev_row = list(range(len(comp_word)+1))\n",
    "    # mx.append(prev_row)\n",
    "    min_err = 0\n",
    "    for i, l1 in enumerate(ref_word):\n",
    "        curr_row = [i+1]\n",
    "        for j, l2 in enumerate(comp_word):\n",
    "            curr_row.append(min([prev_row[j+1]+1, curr_row[j]+1, prev_row[j]+(l1 != l2)]))\n",
    "        if (current_min_err := min(curr_row)) > min_err:\n",
    "            min_err = current_min_err\n",
    "            idx = curr_row.index(min_err)\n",
    "            print(l1, comp_word[idx])\n",
    "            # if curr_row[idx] == curr_row[idx+1]:\n",
    "            #     print(l1, comp_word[idx+1])\n",
    "        # if (idx := np.argwhere(np.subtract(curr_row, prev_row) == 0)):\n",
    "        #     print(l1, comp_word[idx[0][0]-1])\n",
    "        prev_row = curr_row\n",
    "        # mx.append(prev_row)\n",
    "    # print(\"\\n\".join([str(r) for r in mx]))\n",
    "    return prev_row[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for ref, pred in zip(*outputs):\n",
    "    print(str(i) + \":\")\n",
    "    levenstein(ref_word=ref.split(), comp_word=pred.split())\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 10\n",
    "print(dataset[idx][\"sentence\"], outputs[0][idx], outputs[1][idx], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{name: metric.compute(predictions=['okresy nemají v současnosti na rozdíl od krajů právní funkci'], references=[sentence]) for name, metric in metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = wav2vec_processor(input_audio['array'], sampling_rate=SAMPLING_RATE, return_tensors='pt')\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = wav2vec_model(**inputs).logits\n",
    "\n",
    "pred_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = wav2vec_processor.batch_decode(pred_ids)\n",
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = t5_tokenizer([\"spell check: \" + sentence for sentence in transcription], return_tensors=\"pt\")\n",
    "\n",
    "output_sequences = t5_model.generate(**inputs, max_new_tokens=20)\n",
    "\n",
    "t5_tokenizer.batch_decode(output_sequences, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stuff..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_dataset = load_from_disk(\"/home/sulcm/datasets/t5/asr-correction-cs-v23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_dataset[\"test\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"/home/sulcm/models/wav2vec2/wav2vec2-cs-v1/pytorch_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model['wav2vec2.encoder.layers.11.final_layer_norm.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model['lm_head.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
