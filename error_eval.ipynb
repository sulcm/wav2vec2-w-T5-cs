{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, BertTokenizer, BertModel\n",
    "from datasets import Dataset, load_from_disk\n",
    "import evaluate\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "from rapidfuzz.distance import Levenshtein, Opcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_RATE = 16_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T5_MODEL_NAME = \"/home/sulcm/models/t5/t5-spellchecker-cs-v20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"/home/sulcm/datasets/t5/asr-correction-cs-v23/test\")\n",
    "# dataset = load_from_disk(\"/home/sulcm/datasets/t5/asr-correction-commonvoice-test-cs-v23/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and compute eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"spell check: \"\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(T5_MODEL_NAME)\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained(T5_MODEL_NAME).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_correction_and_results = {\n",
    "    \"t5_correction\": [],\n",
    "    \"w2v2_vs_target_wer\": [],\n",
    "    \"t5_vs_target_wer\": [],\n",
    "    \"w2v2_vs_t5_wer\": []\n",
    "}\n",
    "\n",
    "for ds_row in tqdm(dataset):\n",
    "    # asr_transcription, target_output\n",
    "    inputs = t5_tokenizer(prefix + ds_row[\"asr_transcription\"], return_tensors=\"pt\").to(device)\n",
    "    output_sequences = t5_model.generate(**inputs, max_new_tokens=64, num_beams=4, do_sample=True)\n",
    "    corrected_input = t5_tokenizer.batch_decode(output_sequences, skip_special_tokens=True)\n",
    "\n",
    "    t5_correction_and_results[\"w2v2_vs_target_wer\"].append(wer_metric.compute(predictions=(ds_row[\"asr_transcription\"],), references=(ds_row[\"target_output\"],)))\n",
    "    t5_correction_and_results[\"t5_vs_target_wer\"].append(wer_metric.compute(predictions=corrected_input, references=(ds_row[\"target_output\"],)))\n",
    "    t5_correction_and_results[\"w2v2_vs_t5_wer\"].append(wer_metric.compute(predictions=(ds_row[\"asr_transcription\"],), references=corrected_input))\n",
    "    t5_correction_and_results[\"t5_correction\"].extend(corrected_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"./data/error_eval_commonvoice_ds_v23_test_w_t5_v20.json\", \"w\") as f:\n",
    "#     json.dump(t5_correction_and_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/error_eval_voxpopuli_ds_v23_test_w_t5_v20.json\", \"r\") as f:\n",
    "    t5_correction_and_results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ST6ErrorAnalysis():\n",
    "    def __init__(self, classes_def_path: str=\"\") -> None:\n",
    "        word_classes_file = {}\n",
    "        if classes_def_path:\n",
    "            with open(classes_def_path, \"r\") as f:\n",
    "                word_classes_file = json.load(f)\n",
    "\n",
    "        self.word_classes_by_label = word_classes_file.get(\"definitions\", {})\n",
    "        self.id2label = word_classes_file.get(\"classes\", [])\n",
    "        self.label2id = {l: i for i, l in enumerate(self.id2label)}\n",
    "        \n",
    "        self.test_methods = [self.is_preposition,\n",
    "                             self.is_conjunction,\n",
    "                             self.is_prefix,\n",
    "                             self.is_iy,\n",
    "                             self.is_uu,\n",
    "                             self.is_szc,\n",
    "                             self.is_dt,\n",
    "                             self.is_gk,\n",
    "                             self.is_bp,]\n",
    "\n",
    "        pass\n",
    "\n",
    "    def get_error_classes(self, lev_ops: dict) -> list[dict]:\n",
    "        errors = []\n",
    "        for action, model_output, reference in zip(lev_ops[\"action\"], lev_ops[\"model_output\"], lev_ops[\"reference\"]):\n",
    "            match action:\n",
    "                case \"delete\":\n",
    "                    errors.append(self.resolve_error_tests([test_fcn(action, reference) for test_fcn in self.test_methods], reference, action))\n",
    "                case \"insert\":\n",
    "                    errors.append(self.resolve_error_tests([test_fcn(action, model_output) for test_fcn in self.test_methods], model_output, action))\n",
    "                case \"replace\":\n",
    "                    replaced = (model_output[0], reference[0])\n",
    "                    errors.append(self.resolve_error_tests([test_fcn(action, replaced) for test_fcn in self.test_methods], replaced, action))\n",
    "        return errors\n",
    "\n",
    "    def resolve_error_tests(self, tests: list, tested: tuple[str], operation: str) -> dict:\n",
    "        if any(tests):\n",
    "            res = [err for err in tests if err is not None]\n",
    "        elif tested[0] == \"\" or tested[0] == \" \":\n",
    "            res = []\n",
    "        else:\n",
    "            res = [\"other\"]\n",
    "        \n",
    "        space_err = self.check_spaces(operation, tested)\n",
    "        if space_err:\n",
    "            res.append(space_err)\n",
    "        \n",
    "        return {operation: res}\n",
    "\n",
    "    def check_spaces(self, operation: str, op: tuple[str]) -> str|None:\n",
    "        val = op[0]\n",
    "        context = op[1].split(\" \")\n",
    "        if val == \"\" and len(context) == 1:\n",
    "            return \"removed_space\"\n",
    "        elif \" \" in val and len(context) > 1:\n",
    "            if operation == \"delete\":\n",
    "                return \"removed_space\"\n",
    "            else:\n",
    "                return \"added_space\"\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def is_preposition(self, operation: str, op: tuple[str]) -> str|None:\n",
    "        val = op[0].strip()\n",
    "        context = op[1].split(\" \")\n",
    "        if val in self.word_classes_by_label[\"prepositions\"] and val in context:\n",
    "            return \"prepositions\"\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def is_conjunction(self, operation: str, op: tuple[str]) -> str|None:\n",
    "        val = op[0].strip()\n",
    "        context = op[1].split(\" \")\n",
    "        if val in self.word_classes_by_label[\"conjunctions\"] and val in context:\n",
    "            return \"conjunctions\"\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def is_prefix(self, operation: str, op: tuple[str]) -> str|None:\n",
    "        val = op[0].strip()\n",
    "        context = op[1].split(\" \")\n",
    "        if val in self.word_classes_by_label[\"prefixes\"] and any([c.startswith(val) and len(c) > len(val) for c in context]):\n",
    "            return \"prefixes\"\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def is_iy(self, operation: str, op: tuple[str]) -> str|None:\n",
    "        val = op[0].strip()\n",
    "        context = op[1].strip()\n",
    "        if val in self.word_classes_by_label[\"iy\"] and context in self.word_classes_by_label[\"iy\"] and val != context:\n",
    "            return \"iy\"\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def is_uu(self, operation: str, op: tuple[str]) -> str|None:\n",
    "        val = op[0].strip()\n",
    "        context = op[1].strip()\n",
    "        if val in self.word_classes_by_label[\"uu\"] and context in self.word_classes_by_label[\"uu\"] and val != context:\n",
    "            return \"uu\"\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def is_szc(self, operation: str, op: tuple[str]) -> str|None:\n",
    "        val = op[0].strip()\n",
    "        context = op[1].strip()\n",
    "        if val in self.word_classes_by_label[\"szc\"] and context in self.word_classes_by_label[\"szc\"] and val != context:\n",
    "            return \"szc\"\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def is_dt(self, operation: str, op: tuple[str]) -> str|None:\n",
    "        val = op[0].strip()\n",
    "        context = op[1].strip()\n",
    "        if val in self.word_classes_by_label[\"dt\"] and context in self.word_classes_by_label[\"dt\"] and val != context:\n",
    "            return \"dt\"\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def is_gk(self, operation: str, op: tuple[str]) -> str|None:\n",
    "        val = op[0].strip()\n",
    "        context = op[1].strip()\n",
    "        if val in self.word_classes_by_label[\"gk\"] and context in self.word_classes_by_label[\"gk\"] and val != context:\n",
    "            return \"gk\"\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def is_bp(self, operation: str, op: tuple[str]) -> str|None:\n",
    "        val = op[0].strip()\n",
    "        context = op[1].strip()\n",
    "        if val in self.word_classes_by_label[\"bp\"] and context in self.word_classes_by_label[\"bp\"] and val != context:\n",
    "            return \"bp\"\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def analyse_error_classes(self, dataset_idxs: list|set|str, ds_model_output: list, ds_target_output: list, operations: list=[\"delete\", \"insert\", \"replace\"], return_raw_pd: bool=False) -> dict[dict]|pd.DataFrame:\n",
    "        if dataset_idxs == \"all\":\n",
    "            dataset_idxs = range(len(ds_target_output))\n",
    "        if isinstance(dataset_idxs, str):\n",
    "            raise ValueError('String can not refer to list items. Please provide list/set or string \"all\" for iterating thru all items.')\n",
    "        \n",
    "        err_analysis = []\n",
    "        for test_idx in dataset_idxs:\n",
    "            idx = int(test_idx)\n",
    "            lev_ops = self.levenshtein_ops(model_output=ds_model_output[idx], reference=ds_target_output[idx])\n",
    "            if return_raw_pd:\n",
    "                err_analysis.append(self.get_error_classes(lev_ops))\n",
    "            else:\n",
    "                err_analysis.extend(self.get_error_classes(lev_ops))\n",
    "        \n",
    "        if return_raw_pd:\n",
    "            return pd.DataFrame.from_records(err_analysis)\n",
    "        else:\n",
    "            error_classes_counts = {}\n",
    "            for op in operations:\n",
    "                class_counts = dict.fromkeys(self.id2label, 0)\n",
    "                class_counts.update(pd.DataFrame.from_records(err_analysis)[op].dropna().explode().value_counts().to_dict())\n",
    "                error_classes_counts[op] = class_counts\n",
    "            \n",
    "            return error_classes_counts\n",
    "    \n",
    "    def plot_error_analysis(self, err_analysis: dict, title: str=None, save_path: str=None) -> None:\n",
    "        fig, axes = plt.subplots(ncols=len(err_analysis))\n",
    "        fig.set_figwidth(12)\n",
    "        if title:\n",
    "            fig.suptitle(title)\n",
    "        \n",
    "        for i, (action, stats) in enumerate(err_analysis.items()):\n",
    "            axes[i].bar(stats.keys(), stats.values())\n",
    "            axes[i].tick_params(axis='x', labelrotation=90)\n",
    "            axes[i].set_title(action)\n",
    "            axes[i].bar_label(axes[i].containers[0], label_type='edge')\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, pad_inches=0.05, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    @staticmethod\n",
    "    def levenshtein_ops(model_output: str, reference: str) -> dict:\n",
    "        lev_ops = Levenshtein.editops(reference, model_output)\n",
    "        lev_ops_dict = {\n",
    "            \"action\": [],\n",
    "            \"model_output\": [],\n",
    "            \"reference\": [],\n",
    "        }\n",
    "        for ops in Opcodes.from_editops(lev_ops):\n",
    "            if ops.tag != \"equal\":\n",
    "                lev_ops_dict[\"action\"].append(ops.tag)\n",
    "                lev_ops_dict[\"reference\"].append((reference[ops.src_start:ops.src_end],\n",
    "                                            (src_start[-1] if (src_start := reference[:ops.src_start].split(\" \")) else \"\") + \n",
    "                                            reference[ops.src_start:ops.src_end] + \n",
    "                                            (src_end[0] if (src_end := reference[ops.src_end:].split(\" \")) else \"\")))\n",
    "                lev_ops_dict[\"model_output\"].append((model_output[ops.dest_start:ops.dest_end], \n",
    "                                            (dest_start[-1] if (dest_start := model_output[:ops.dest_start].split(\" \")) else \"\") + \n",
    "                                            model_output[ops.dest_start:ops.dest_end] + \n",
    "                                            (dest_end[0] if (dest_end := model_output[ops.dest_end:].split(\" \")) else \"\")))\n",
    "        return lev_ops_dict\n",
    "\n",
    "\n",
    "st6_error_analysis = ST6ErrorAnalysis(\"./word_classes_definitions.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_outputs(idx: int) -> None:\n",
    "    print(\n",
    "        f\"W2V2 Transcription (WER = {t5_correction_and_results['w2v2_vs_target_wer'][idx]:.4f}): \" + dataset[idx]['asr_transcription'],\n",
    "        f\"     T5 Correction (WER = {t5_correction_and_results['t5_vs_target_wer'][idx]:.4f}): \" + t5_correction_and_results['t5_correction'][idx],\n",
    "        \"                    Target output: \" + dataset[idx]['target_output'],\n",
    "        sep=\"\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_errors_df = st6_error_analysis.analyse_error_classes(\"all\", t5_correction_and_results['t5_correction'], dataset[\"target_output\"], return_raw_pd=True)\n",
    "t5_errors_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_errors_df.notnull().sum(axis=1).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_errors_df.notnull().sum(axis=1).where(lambda x: x > 40).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 834\n",
    "st6_error_analysis.levenshtein_ops(t5_correction_and_results['t5_correction'][idx], dataset[idx][\"target_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lev_ops = st6_error_analysis.levenshtein_ops(t5_correction_and_results['t5_correction'][834], dataset[834][\"target_output\"])\n",
    "lev_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_outputs(834)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_errors = st6_error_analysis.analyse_error_classes(\"all\", t5_correction_and_results['t5_correction'], dataset[\"target_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st6_error_analysis.plot_error_analysis(t5_errors, title=\"Chyby v operacích zavedené modelem T5 na požadovaný výstup\")\n",
    "# st6_error_analysis.plot_error_analysis(t5_errors, save_path=\"/home/sulcm/school/BP/pics/ops_t5_voxpopuli.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v2_errors_df = st6_error_analysis.analyse_error_classes(\"all\", dataset[\"asr_transcription\"], dataset[\"target_output\"], return_raw_pd=True)\n",
    "w2v2_errors_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v2_errors_df.notnull().sum(axis=1).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v2_errors_df.notnull().sum(axis=1).where(lambda x: x > 40).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v2_errors = st6_error_analysis.analyse_error_classes(\"all\", dataset[\"asr_transcription\"], dataset[\"target_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st6_error_analysis.plot_error_analysis(w2v2_errors, title=\"Chyby v operacích zavedené modelem Wav2Vec2.0 na požadovaný výstup\")\n",
    "# st6_error_analysis.plot_error_analysis(w2v2_errors, save_path=\"/home/sulcm/school/BP/pics/ops_w2v2_voxpopuli.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5 mistakes on ***correct*** W2V2 transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_w2v2_transcription = np.argwhere(np.transpose(t5_correction_and_results[\"w2v2_vs_target_wer\"]) == 0.0).flatten()\n",
    "incorrect_t5_correction = np.argwhere(np.transpose(t5_correction_and_results[\"t5_vs_target_wer\"]) > 0.0).flatten()\n",
    "correct_asr_transcription_incorect_t5_correction = set(correct_w2v2_transcription).intersection(set(incorrect_t5_correction))\n",
    "len(correct_asr_transcription_incorect_t5_correction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5 good corrections on ***bad*** W2V2 transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_w2v2_transcription = np.argwhere(np.transpose(t5_correction_and_results[\"w2v2_vs_target_wer\"]) > 0.0).flatten()\n",
    "correct_t5_correction = np.argwhere(np.transpose(t5_correction_and_results[\"t5_vs_target_wer\"]) == 0.0).flatten()\n",
    "correct_t5_correction_on_bad_asr_transcription = set(correct_t5_correction).intersection(set(incorrect_w2v2_transcription))\n",
    "len(correct_t5_correction_on_bad_asr_transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct ASR and correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_asr_w_correction = set(correct_w2v2_transcription).intersection(set(correct_t5_correction))\n",
    "len(correct_asr_w_correction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorrect ASR and incorrect correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_asr_w_correction = set(incorrect_w2v2_transcription).intersection(set(incorrect_t5_correction))\n",
    "incorrect_asr_w_correction_idx = list(incorrect_asr_w_correction)\n",
    "len(incorrect_asr_w_correction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Less incorrect ASR (T5 corrected some mistakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_incorrect_asr_idx = np.argwhere(np.array(t5_correction_and_results[\"w2v2_vs_target_wer\"])[incorrect_asr_w_correction_idx] > np.array(t5_correction_and_results[\"t5_vs_target_wer\"])[incorrect_asr_w_correction_idx]).flatten()\n",
    "less_incorrect_asr = set(np.array(incorrect_asr_w_correction_idx)[less_incorrect_asr_idx])\n",
    "len(less_incorrect_asr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More incorrect ASR (T5 made more mistakes then repaired) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_incorrect_asr_idx = np.argwhere(np.array(t5_correction_and_results[\"w2v2_vs_target_wer\"])[incorrect_asr_w_correction_idx] < np.array(t5_correction_and_results[\"t5_vs_target_wer\"])[incorrect_asr_w_correction_idx]).flatten()\n",
    "more_incorrect_asr = set(np.array(incorrect_asr_w_correction_idx)[more_incorrect_asr_idx])\n",
    "len(more_incorrect_asr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equally as bad ASR and T5 correnction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_incorrect_asr_idx = np.argwhere(np.array(t5_correction_and_results[\"w2v2_vs_target_wer\"])[incorrect_asr_w_correction_idx] == np.array(t5_correction_and_results[\"t5_vs_target_wer\"])[incorrect_asr_w_correction_idx]).flatten()\n",
    "eq_incorrect_asr = set(np.array(incorrect_asr_w_correction_idx)[eq_incorrect_asr_idx])\n",
    "len(eq_incorrect_asr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring semantic closeness between reference sentence and infered ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained(\"fav-kky/FERNET-C5\")\n",
    "bert_model = BertModel.from_pretrained(\"fav-kky/FERNET-C5\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = torch.nn.CosineSimilarity(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_sim = {\n",
    "    \"sim_w2v2_to_ref\": [],\n",
    "    \"sim_t5_to_ref\": []\n",
    "}\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    ref = dataset[i][\"target_output\"]\n",
    "    \n",
    "    inputs = bert_tokenizer([dataset[i][\"asr_transcription\"], ref], padding=True, return_tensors=\"pt\").to(device)\n",
    "    cls_emb = bert_model(**inputs).last_hidden_state[:, 0, :]\n",
    "    semantic_sim[\"sim_w2v2_to_ref\"].append(cosine_sim.forward(cls_emb[0], cls_emb[1]).item())\n",
    "\n",
    "    inputs = bert_tokenizer([t5_correction_and_results[\"t5_correction\"][i], ref], padding=True, return_tensors=\"pt\").to(device)\n",
    "    cls_emb = bert_model(**inputs).last_hidden_state[:, 0, :]\n",
    "    semantic_sim[\"sim_t5_to_ref\"].append(cosine_sim.forward(cls_emb[0], cls_emb[1]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"./data/embeddings_commonvoice_cos_sim_w2v2v23_t5v20.json\", \"w\") as f:\n",
    "#     json.dump(semantic_sim, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/embeddings_commonvoice_cos_sim_w2v2v23_t5v20.json\", \"r\") as f:\n",
    "    semantic_sim = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/embeddings_commonvoice_cos_sim_w2v2v23_t5v20.json\", \"r\") as f:\n",
    "    semantic_sim_v20 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/embeddings_commonvoice_cos_sim_w2v2v23_t5v4.json\", \"r\") as f:\n",
    "    semantic_sim_v4 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(semantic_sim_v4[\"sim_w2v2_to_ref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(semantic_sim_v4[\"sim_w2v2_to_ref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(semantic_sim_v4[\"sim_w2v2_to_ref\"], 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test = scipy.stats.ttest_ind(semantic_sim_v4[\"sim_w2v2_to_ref\"], semantic_sim_v4[\"sim_t5_to_ref\"])\n",
    "t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_comp = (np.mean(semantic_sim_v4[\"sim_w2v2_to_ref\"]) - np.mean(semantic_sim_v4[\"sim_t5_to_ref\"])) / np.sqrt((np.var(semantic_sim_v4[\"sim_w2v2_to_ref\"], ddof=2) + np.var(semantic_sim_v4[\"sim_t5_to_ref\"], ddof=2)) / len(semantic_sim_v4[\"sim_t5_to_ref\"]))\n",
    "ttest_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = plt.boxplot((semantic_sim_v4[\"sim_w2v2_to_ref\"], semantic_sim_v4[\"sim_t5_to_ref\"], semantic_sim_v20[\"sim_t5_to_ref\"]),\n",
    "            vert=True,\n",
    "            patch_artist=True,\n",
    "            labels=[\"W2V2v23\", \"+ T5v4\", \"+ T5v20\"],\n",
    "            )\n",
    "fliers = bp[\"fliers\"]\n",
    "for flier in fliers:\n",
    "    flier_data = flier.get_data()\n",
    "    one_perc_fliers_idx = np.argwhere(flier_data[1] < np.percentile(flier_data[1], 1)).flatten()\n",
    "    flier.set_data(tuple([fly[one_perc_fliers_idx] for fly in flier_data]))\n",
    "plt.ylabel(\"sim(x, reference)\")\n",
    "plt.savefig(\"/home/sulcm/school/BP/pics/cos_sim_voxpopuli.pdf\", pad_inches=0.05, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(semantic_sim[\"sim_w2v2_to_ref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(semantic_sim[\"sim_t5_to_ref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(semantic_sim[\"sim_w2v2_to_ref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere(np.array(semantic_sim[\"sim_w2v2_to_ref\"]) < 0.2).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(semantic_sim[\"sim_w2v2_to_ref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(semantic_sim[\"sim_w2v2_to_ref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(semantic_sim[\"sim_t5_to_ref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(semantic_sim[\"sim_t5_to_ref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[441][\"asr_transcription\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_correction_and_results[\"t5_correction\"][441]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[441][\"target_output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 750\n",
    "w2v2_output=dataset[idx][\"asr_transcription\"]\n",
    "t5_output=t5_correction_and_results[\"t5_correction\"][idx]\n",
    "ref = dataset[idx][\"target_output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v2_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = bert_tokenizer([t5_output, ref], padding=True, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = bert_model(**inputs)\n",
    "cls_emb = embeddings.last_hidden_state[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim.forward(cls_emb[0], cls_emb[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphodita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ufal.morphodita import Morpho, Tagger, TaggedLemmas, TokenRanges, Forms, Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_entities(text: str):\n",
    "    return text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;').replace('\"', '&quot;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# morpho = Morpho.load(\"data/czech-morfflex2.0-pdtc1.0-220710/czech-morfflex2.0-220710.dict\")\n",
    "tagger = Tagger.load(\"data/czech-morfflex2.0-pdtc1.0-220710/czech-morfflex2.0-pdtc1.0-220710.tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forms = Forms()\n",
    "lemmas = TaggedLemmas()\n",
    "tokens = TokenRanges()\n",
    "# analyses = Analyses()\n",
    "tokenizer = tagger.newTokenizer()\n",
    "# tagger.tagAnalyzed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = \"r\"\n",
    "tokenizer.setText(line)\n",
    "\n",
    "t = 0\n",
    "while tokenizer.nextSentence(forms, tokens):\n",
    "    tagger.tag(forms, lemmas)\n",
    "    for i in range(len(lemmas)):\n",
    "        lemma = lemmas[i]\n",
    "        token = tokens[i]\n",
    "        # tagger.tagAnalyzed(token, lemma.lemma, lemma.tag)\n",
    "        print('%s\\t<token lemma=\"%s\" tag=\"%s\">%s</token>%s' % (\n",
    "        # encode_entities(line[t : token.start]),\n",
    "        \"<sentence>\\n\" if i == 0 else \"\",\n",
    "        encode_entities(lemma.lemma),\n",
    "        encode_entities(lemma.tag),\n",
    "        encode_entities(line[token.start : token.start + token.length]),\n",
    "        \"\\n</sentence>\" if i + 1 == len(lemmas) else \"\",\n",
    "        ), sep=\"\\n\")\n",
    "        t = token.start + token.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
